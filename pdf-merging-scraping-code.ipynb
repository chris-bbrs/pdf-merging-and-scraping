{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from io import StringIO\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.high_level import extract_text_to_fp\n",
    "import os\n",
    "from natsort import natsorted\n",
    "import PyPDF2\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "import joblib\n",
    "import stop_words #greek stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = 'stoch'\n",
    "\n",
    "files = natsorted([os.path.join(mypath, f) for f in os.listdir(mypath) if f.endswith('.pdf')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stoch\\\\ElearningStoch1.pdf',\n",
       " 'stoch\\\\ElearningStoch2.pdf',\n",
       " 'stoch\\\\ElearningStoch3.pdf',\n",
       " 'stoch\\\\Periodikotita.pdf',\n",
       " 'stoch\\\\Stoch1.pdf',\n",
       " 'stoch\\\\Stoch2e.pdf',\n",
       " 'stoch\\\\StochasticAskiseis.pdf',\n",
       " 'stoch\\\\basic.pdf',\n",
       " 'stoch\\\\eksisoseisdiaforon.pdf',\n",
       " 'stoch\\\\mesosxronosipopriop.pdf',\n",
       " 'stoch\\\\perigrafi.pdf',\n",
       " 'stoch\\\\tixaiosperipatos.pdf',\n",
       " 'stoch\\\\ypologismosxaraktiristikou.pdf']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Merge pdf files\n",
    "pdfWriter = PyPDF2.PdfFileWriter()\n",
    "\n",
    "chapters = []\n",
    "#loop through all PDFs\n",
    "for filename in files:\n",
    "    #rb for read binary\n",
    "    pdfFileObj = open(filename, 'rb')\n",
    "    pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "    \n",
    "    #Opening each page of the PDF\n",
    "    for pageNum in range(pdfReader.numPages):\n",
    "        pageObj = pdfReader.getPage(pageNum)\n",
    "        pdfWriter.addPage(pageObj)\n",
    "    chapters.append(pageNum+1)\n",
    "    \n",
    "chapters = np.cumsum(chapters)\n",
    "#save PDF to file, wb for write binary\n",
    "pdfOutput = open('merged_stoch'+'.pdf', 'wb')\n",
    "#Outputting the PDF\n",
    "pdfWriter.write(pdfOutput)\n",
    "#Closing the PDF writer\n",
    "pdfOutput.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7,  11,  19,  23,  30,  36,  45,  46,  63,  72,  74,  87, 104],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(chapters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_string = StringIO()\n",
    "with open('./merged_stoch.pdf', 'rb') as fin:\n",
    "    extract_text_to_fp(fin, output_string, laparams=LAParams(),output_type='html', codec=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = output_string.getvalue()\n",
    "bs = BeautifulSoup(contents, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spans = bs.find_all('span', style=re.compile(r\"(border: black 1px solid|border: gray 1px solid|border: figure 1px solid)\"))\n",
    "for sp in spans:\n",
    "    sp.decompose()\n",
    "    \n",
    "spans = bs.find_all('div', style=re.compile(r\"(border: figure 1px solid)\"))\n",
    "for sp in spans:\n",
    "    sp.decompose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentence):\n",
    "    sentence=str(sentence)\n",
    "    sentence = sentence.lower()\n",
    "    sentence=sentence.replace('{html}',\"\")\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', sentence)\n",
    "    rem_url=re.sub(r'http\\S+', '',cleantext)\n",
    "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
    "    rem_symb = re.sub(r\"\\W+|_\", \" \", rem_num)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(rem_symb)\n",
    "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stop_words.el()]\n",
    "    stem_words=[stemmer.stem(w) for w in filtered_words]\n",
    "    lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
    "    return \" \".join(filtered_words)\n",
    "# df['cleanText']=df['Text'].map(lambda s:preprocess(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = defaultdict(list)\n",
    "divs = bs.find_all('div')\n",
    "y = []\n",
    "chapt = 0\n",
    "for tst in divs:\n",
    "    if re.search(\"^position:absolute; top:.*px;$\", tst.attrs['style']):\n",
    "        try:\n",
    "            d[tst.a['name']] = ''\n",
    "            index = str(tst.a['name'])\n",
    "            y.append(chapt)\n",
    "        except:\n",
    "            continue\n",
    "    else:\n",
    "        d[index] += ' ' + preprocess(tst.text)\n",
    "        \n",
    "    try:\n",
    "        if int(index) >= chapters[chapt]:\n",
    "            chapt += 1\n",
    "    except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>κεφÿαλαιο μαρκοβιανÿες αλυσÿιδες διακριτοÿυ ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>επαναληπτικÿες μεταβατικÿες καταστÿασεις  επι...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>κεφÿαλαιο μαρκοβιανÿες αλυσÿιδες διακριτοÿυ ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>πιθανÿοτητες χρÿονοι πρÿωτης εισÿοδου  καταστ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>πιθανÿοτητες χρÿονοι πρÿωτης εισÿοδου  υπολογ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>πιθανÿοτητες χρÿονοι πρÿωτης εισÿοδου  θέτοντ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>κεφÿαλαιο μαρκοβιανÿες αλυσÿιδες διακριτοÿυ ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>πιθανÿοτητες χρÿονοι πρÿωτης εισÿοδου  υπολογ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>κεφÿαλαιο μαρκοβιανÿες αλυσÿιδες διακριτοÿυ ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>πιθανÿοτητες χρÿονοι πρÿωτης εισÿοδου  θέτοντ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>κεφÿαλαιο μαρκοβιανÿες αλυσÿιδες διακριτοÿυ ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>οριακÿες πιθανÿοτητες  μαρκοβιανή αλυσίδα δια...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  y\n",
       "0     κεφÿαλαιο μαρκοβιανÿες αλυσÿιδες διακριτοÿυ ...  0\n",
       "1    επαναληπτικÿες μεταβατικÿες καταστÿασεις  επι...  0\n",
       "2     κεφÿαλαιο μαρκοβιανÿες αλυσÿιδες διακριτοÿυ ...  0\n",
       "3    πιθανÿοτητες χρÿονοι πρÿωτης εισÿοδου  καταστ...  0\n",
       "4    πιθανÿοτητες χρÿονοι πρÿωτης εισÿοδου  υπολογ...  0\n",
       "5    πιθανÿοτητες χρÿονοι πρÿωτης εισÿοδου  θέτοντ...  0\n",
       "6     κεφÿαλαιο μαρκοβιανÿες αλυσÿιδες διακριτοÿυ ...  0\n",
       "7    πιθανÿοτητες χρÿονοι πρÿωτης εισÿοδου  υπολογ...  1\n",
       "8     κεφÿαλαιο μαρκοβιανÿες αλυσÿιδες διακριτοÿυ ...  1\n",
       "9    πιθανÿοτητες χρÿονοι πρÿωτης εισÿοδου  θέτοντ...  1\n",
       "10    κεφÿαλαιο μαρκοβιανÿες αλυσÿιδες διακριτοÿυ ...  1\n",
       "11   οριακÿες πιθανÿοτητες  μαρκοβιανή αλυσίδα δια...  2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(d, orient='index', dtype='str')\n",
    "df = df.reset_index(drop=True)\n",
    "df['y'] = y\n",
    "df = df.rename(columns={0: 'text'})\n",
    "df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_df(x_data=pd.Series([])):\n",
    "    if not x_data.empty:\n",
    "        tfidf_tweets = x_data\n",
    "\n",
    "        tfidf_vectorizer = TfidfVectorizer(preprocessor=preprocess)\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(tfidf_tweets)\n",
    "\n",
    "        dense = pd.DataFrame(tfidf_matrix.todense(), columns=tfidf_vectorizer.get_feature_names())\n",
    "\n",
    "        return dense\n",
    "\n",
    "# vectorize_dt(df.iloc[0], df['y'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineLR = Pipeline([\n",
    "    ('vectorize', TfidfVectorizer(preprocessor=preprocess)),\n",
    "    ('classifier', LogisticRegression()),\n",
    "])\n",
    "\n",
    "pipelineNB = Pipeline([\n",
    "    ('vectorize', TfidfVectorizer(preprocessor=preprocess)),\n",
    "    ('classifier', MultinomialNB()),\n",
    "])\n",
    "\n",
    "pipelineLR.fit(df['text'], df['y']);\n",
    "pipelineNB.fit(df['text'], df['y']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(pipelineNB, 'pdf_stoch100%_NV.joblib');\n",
    "joblib.dump(pipelineLR, 'pdf_stoch100%_LogReg.joblib');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Υπολογίστε τις οριακές πιθανότητες σε όλες τις Μαρκοβιανές αλυσίδες των προηγούμενων ϕυλλαδίων.\n",
      "Naive Bayes: 12\n",
      "Logistic Regression: 12\n"
     ]
    }
   ],
   "source": [
    "NB = joblib.load('pdf_stoch100%_NV.joblib')\n",
    "LR = joblib.load('pdf_stoch100%_LogReg.joblib')\n",
    "\n",
    "txt = input()\n",
    "print('Naive Bayes:', NB.predict(pd.Series(txt))[0])\n",
    "print('Logistic Regression:', LR.predict(pd.Series(txt))[0])"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
